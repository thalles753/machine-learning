Simulator.run(): Trial 0
Environment.reset(): Trial set up with start = (1, 4), destination = (7, 6), deadline = 40
RoutePlanner.route_to(): destination = (7, 6)
Q action: 0 Action:  None
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
red_light [ 0.  0.  0.  0.]
None
Random action prob:  0.932635010228
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
red_light [ 0.  -0.5  0.   0. ]
None
Random action prob:  0.900673887199
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
red_light [ 0.         -0.5        -0.33333333  0.        ]
None
Q action: 0 Action:  None
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
red_light [ 0.         -0.5        -0.33333333  0.        ]
None
Random action prob:  0.84
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
red_light [ 0.         -0.5        -0.46666667  0.        ]
None
Random action prob:  0.811213451082
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
green_light [ 0.          0.          0.          0.33333333]
red_light [ 0.         -0.5        -0.46666667  0.        ]
None
Random action prob:  0.783413408592
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
green_light [ 0.03809524  0.          0.          0.33333333]
red_light [ 0.         -0.5        -0.46666667  0.        ]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
green_light [ 0.03809524  0.          0.          0.575     ]
red_light [ 0.         -0.5        -0.46666667  0.        ]
None
Random action prob:  0.730638772334
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
green_light [ 0.03809524  0.          0.          0.575     ]
red_light [ 0.         -0.5        -0.52592593  0.        ]
None
Random action prob:  0.7056
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
green_light [ 0.03809524  0.          0.          0.575     ]
red_light [ 0.         -0.5        -0.57333333  0.        ]
None
Random action prob:  0.681419298909
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
green_light [ 0.03809524  0.          0.          0.575     ]
red_light [ 0.         -0.5        -0.57333333 -0.00363636]
None
Random action prob:  0.658067263217
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
green_light [ 0.07325397  0.          0.          0.575     ]
red_light [ 0.         -0.5        -0.57333333 -0.00363636]
None
Random action prob:  0.635515494808
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
green_light [ 0.07325397  0.          0.          0.49230769]
red_light [ 0.         -0.5        -0.57333333 -0.00363636]
None
Random action prob:  0.613736568761
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
green_light [ 0.07325397  0.          0.          0.49230769]
red_light [ 0.         -0.5        -0.57333333  0.16761239]
None
Random action prob:  0.592704
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.         -0.5        -0.57333333  0.16761239]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.         -0.5        -0.57333333  0.306752  ]
None
Random action prob:  0.552776501102
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.         -0.5        -0.58399598  0.306752  ]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.         -0.5        -0.58399598  0.27556586]
None
Random action prob:  0.515538717759
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.         -0.51471302 -0.58399598  0.27556586]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.         -0.51471302 -0.58399598  0.25647988]
None
Q action: 0 Action:  None
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = None, reward = 0.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.         -0.51471302 -0.58399598  0.25647988]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.         -0.51471302 -0.58399598  0.34505733]
None
Random action prob:  0.448419733136
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.01200199 -0.51471302 -0.58399598  0.34505733]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.01200199 -0.51471302 -0.58399598  0.43042354]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.01200199 -0.51471302 -0.58399598  0.40896044]
None
Random action prob:  0.403879944141
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.01200199 -0.5207945  -0.58399598  0.40896044]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.49230769]
red_light [ 0.01200199 -0.5207945  -0.58399598  0.38988213]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.55729334]
red_light [ 0.01200199 -0.5207945  -0.58399598  0.38988213]
None
Random action prob:  0.363764119251
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.55729334]
red_light [ 0.01200199 -0.52656346 -0.58399598  0.38988213]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.55729334]
red_light [ 0.01200199 -0.52656346 -0.58399598  0.45841388]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.53756886]
red_light [ 0.01200199 -0.52656346 -0.58399598  0.45841388]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.51660518]
red_light [ 0.01200199 -0.52656346 -0.58399598  0.45841388]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.51660518]
red_light [ 0.01200199 -0.52656346 -0.58399598  0.51765238]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.51660518]
red_light [ 0.01200199 -0.52656346 -0.58399598  0.57343089]
None
Q action: 3 Action:  right
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
red_light_left_going_forward [ 0.  0.  0.  0.]
green_light [ 0.09462678  0.          0.          0.51660518]
red_light [ 0.01200199 -0.52656346 -0.58399598  0.55456956]
None
