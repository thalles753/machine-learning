{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thalles/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import pdb\n",
    "from time import sleep\n",
    "import pdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from scipy import misc\n",
    "from skimage import color\n",
    "from collections import deque\n",
    "import random\n",
    "%matplotlib inline\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PIXEL_DEPTH=255.\n",
    "IMAGE_SIZE=84\n",
    "def process_input(img):\n",
    "    out = img[:171, :] # get only the playing area of the image\n",
    "    out = misc.imresize(out, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "    r, g, b = out[:,:,0], out[:,:,1], out[:,:,2]\n",
    "    out = r * (299./1000.) + r * (587./1000.) + b * (114./1000.)\n",
    "    out = (out - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GAME_NAME=\"MsPacman-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-10-03 17:26:07,598] Making new env: MsPacman-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image origial shape: (210, 160, 3)\n",
      "New image shape: (84, 84)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119ee57d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD/CAYAAADRymv0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119b0c190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(GAME_NAME)\n",
    "env.reset()\n",
    "\n",
    "img = env.render('rgb_array')\n",
    "print \"Image origial shape:\", img.shape\n",
    "# plt.imshow(img, cmap='gray', interpolation='nearest')\n",
    "\n",
    "out = process_input(img)\n",
    "print \"New image shape:\", out.shape\n",
    "plt.imshow(out.squeeze(), cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ACTIONS = env.action_space.n\n",
    "NUM_FRAMES_PER_STATE=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 999\n",
    "\n",
    "def weight_variable(name, shape):\n",
    "  return tf.get_variable(name=name, shape=shape, initializer=tf.contrib.layers.xavier_initializer(seed=SEED))\n",
    "\n",
    "def weight_conv_variable(name, shape):\n",
    "  return tf.get_variable(name=name, shape=shape, \n",
    "                         initializer=tf.contrib.layers.xavier_initializer_conv2d(seed=SEED))\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.zeros_initializer(shape=shape, dtype=tf.float32)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x, strides=[1, 2, 2, 1]):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=strides, padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONV1_DEPTH=16\n",
    "W_conv1 = weight_conv_variable(\"conv1\", [5, 5, NUM_FRAMES_PER_STATE, CONV1_DEPTH])\n",
    "b_conv1 = bias_variable([CONV1_DEPTH])\n",
    "\n",
    "CONV2_DEPTH=32\n",
    "W_conv2 = weight_conv_variable(\"conv2\", [5, 5, CONV1_DEPTH, CONV2_DEPTH])\n",
    "b_conv2 = bias_variable([CONV2_DEPTH])\n",
    "\n",
    "FC1_SIZE = 255\n",
    "W_fc1 = weight_variable(\"fc1\", [21 * 21 * CONV2_DEPTH, FC1_SIZE])\n",
    "b_fc1 = bias_variable([FC1_SIZE])\n",
    "\n",
    "out_layer = weight_variable(\"out1\", [FC1_SIZE, NUM_ACTIONS])\n",
    "bias_layer = bias_variable([NUM_ACTIONS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LearningAgent:\n",
    "    def __init__(self, env):\n",
    "        # game variables and constants\n",
    "        self._env = env\n",
    "        self.state = None\n",
    "        self.ACTION_NAMES = self._env.get_action_meanings()\n",
    "        self.NUM_ACTIONS = env.action_space.n\n",
    "        self.action = 0 # default first action\n",
    "        \n",
    "        # AI variables and constants\n",
    "        self.REPLAY_MEN = 10000 # The paper remember the 1000000 most recent frames\n",
    "        self.exp_replay_list = deque(maxlen=self.REPLAY_MEN)\n",
    "        self.SKIP_FRAME_RATE = 4\n",
    "        self.NUM_FRAMES_PER_STATE = 4\n",
    "        self.OBSERVATION_STEPS = 500\n",
    "        \n",
    "        # Q LEARNING variables and constants\n",
    "        self.STARTER_EPSILON = 1.0\n",
    "        self.learning_rate = 1e-5\n",
    "        self.discount_factor = 0.9\n",
    "        self.MINI_BATCH_SIZE = 32\n",
    "        \n",
    "        # Tensorflow variables\n",
    "        self.SEED = 999\n",
    "        self._session = tf.Session() \n",
    "        self._input = tf.placeholder(tf.float32, shape=(None,) + (IMAGE_SIZE,IMAGE_SIZE,self.NUM_FRAMES_PER_STATE), name=\"input_images\")\n",
    "        self._target = tf.placeholder(tf.float32, [None], name=\"input_targets\")\n",
    "        self._action = tf.placeholder(tf.float32, [None, self.NUM_ACTIONS], name=\"input_actions\")\n",
    "        \n",
    "        # Create Deep model\n",
    "        self.model_output = self.model(self._input)\n",
    "        \n",
    "        self.train_step()\n",
    "        \n",
    "        self._session.run(tf.initialize_all_variables())\n",
    "\n",
    "    def train_step(self):\n",
    "        # train variables\n",
    "        readout_action = tf.reduce_sum(tf.mul(self.model_output, self._action), reduction_indices=1)\n",
    "        self.loss_operation = tf.reduce_mean(tf.square(self._target - readout_action))\n",
    "        self._train_operation = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.loss_operation)\n",
    "        \n",
    "    def model(self, inputs, training=True):        \n",
    "        h_conv1 = tf.nn.relu(conv2d(inputs, W_conv1) + b_conv1)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "        shape = h_pool2.get_shape().as_list()\n",
    "        h_pool_flat = tf.reshape(h_pool2, [-1, shape[1] * shape[2] * shape[3]])\n",
    "        \n",
    "        # First fully connected layer\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool_flat, W_fc1) + b_fc1)\n",
    "        if (training == True):\n",
    "            h_fc1 = tf.nn.dropout(h_fc1, 0.92, seed=self.SEED)\n",
    "        \n",
    "        q_actions = tf.matmul(h_fc1, out_layer) + bias_layer\n",
    "        \n",
    "#         with slim.arg_scope([slim.conv2d, slim.max_pool2d],\n",
    "#                       padding=\"SAME\"):\n",
    "\n",
    "#             with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "#                       activation_fn=tf.nn.relu,\n",
    "#                       weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "\n",
    "#                 net = slim.conv2d(inputs, num_outputs=16, kernel_size=[5,5])\n",
    "#                 net = slim.max_pool2d(net, [2, 2], stride=2)\n",
    "\n",
    "#                 net = slim.conv2d(net, num_outputs=32, kernel_size=[5,5])\n",
    "#                 net = slim.max_pool2d(net, [2, 2], stride=2)\n",
    "\n",
    "#                 net = slim.flatten(net)\n",
    "\n",
    "#                 fc = slim.fully_connected(net, 256)\n",
    "#                 fc = slim.dropout(fc, 0.5)\n",
    "\n",
    "#                 out = slim.fully_connected(fc, self.NUM_ACTIONS, activation_fn=None)\n",
    "\n",
    "        return q_actions\n",
    "    \n",
    "    \n",
    "    def to_one_hot_vec(self, actions):\n",
    "        one_hot = np.zeros((self.MINI_BATCH_SIZE, self.NUM_ACTIONS))\n",
    "        one_hot[np.arange(self.MINI_BATCH_SIZE), actions] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def train(self):\n",
    "        # Sample random minibatch of transitions (s_i, a_i, r_i, s_i+1)\n",
    "        # from the experience replay list\n",
    "        mini_batch = random.sample(self.exp_replay_list, self.MINI_BATCH_SIZE)\n",
    "        previous_states = [d[0] for d in mini_batch]\n",
    "        actions = [d[1] for d in mini_batch]\n",
    "        rewards = [d[2] for d in mini_batch]\n",
    "        current_states = [d[3] for d in mini_batch]\n",
    "        \n",
    "        agents_expected_reward = []\n",
    "        # this gives us the agents expected reward for each action we might take\n",
    "        agents_reward_per_action = self._session.run(self.model_output, feed_dict={self._input: current_states})\n",
    "        \n",
    "        for i in range(len(mini_batch)):\n",
    "            if mini_batch[i][4]:\n",
    "                # this was a terminal frame so there is no future reward...\n",
    "                agents_expected_reward.append(rewards[i])\n",
    "            else:\n",
    "                # compute r_j + γ max Q(s_j, a; θ), \n",
    "                #    where:\n",
    "                #      s_j is the current state\n",
    "                #      θ are the CNNs learned weights\n",
    "                agents_expected_reward.append(\n",
    "                    rewards[i] + self.discount_factor * np.max(agents_reward_per_action[i]))\n",
    "\n",
    "        # Perform a gradient descent step on (y_j − Q(φ_j, a_j; θ))^2\n",
    "        _, loss = self._session.run([self._train_operation, self.loss_operation], feed_dict={\n",
    "            self._input: previous_states,\n",
    "            self._action: self.to_one_hot_vec(actions),\n",
    "            self._target: agents_expected_reward})\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def reset_env(self):\n",
    "        return self._env.reset()\n",
    "\n",
    "    def get_random_action(self):\n",
    "        return self._env.action_space.sample()\n",
    "\n",
    "    def get_action_name(self, action):\n",
    "        return self.ACTION_NAMES[action]\n",
    "    \n",
    "    # for the first step, the state is the same state repeated [STATE_FRAMES] times\n",
    "    def game_initial_setup(self):\n",
    "        observations = process_input(self.reset_env())\n",
    "        self.state = np.stack(tuple(observations for _ in range(self.NUM_FRAMES_PER_STATE)), axis=2)\n",
    "        print \"First state:\", self.state.shape\n",
    "    \n",
    "    def get_next_action(self, step):\n",
    "        out = self.action\n",
    "        # With probability p select a random action (a) otherwise select a = maxaQ∗(φ(st), a; θ)\n",
    "        \n",
    "        p = self.linear_decay(step, decay_step=0.00001)\n",
    "        \n",
    "        if step % self.SKIP_FRAME_RATE == 0:\n",
    "            print \"Epsilon:\", p\n",
    "            if random.random() < p:\n",
    "                out = self.get_random_action()\n",
    "                # print \"Step id:\", step, \"Random Action: \", self.action, \":\", self.get_action_name(self.action)\n",
    "            else:\n",
    "                current_state = np.expand_dims(self.state, axis=0)\n",
    "                q_action = self._session.run(self.model_output, feed_dict={self._input: current_state})\n",
    "                out = np.argmax(q_action)\n",
    "                # print \"Step id:\", step, \"Q Action: \", self.action, \":\", self.get_action_name(self.action)\n",
    "        return out\n",
    "    \n",
    "    # perform an exponential decay method\n",
    "    # the paper recommends a decay_step of 0.0000009\n",
    "    def linear_decay(self, global_step, decay_step):\n",
    "        out = self.STARTER_EPSILON - (decay_step * (global_step + 1.0))\n",
    "        out if (out > 0.1) else 0.1\n",
    "        return out\n",
    "    \n",
    "    def update(self, step):\n",
    "        \n",
    "        self._env.render()\n",
    "\n",
    "        self.action = self.get_next_action(step)\n",
    "\n",
    "        # Execute action a_t in emulator and observe reward r_t and image x_t+1\n",
    "        new_observation, reward, done, info = self._env.step(self.action)\n",
    "        \n",
    "        if step % self.SKIP_FRAME_RATE == 0:\n",
    "            # Set s_t+1 = s_t, a_t, x_t+1 and preprocess s_t+1 = φ(st+1)\n",
    "            new_observation = process_input(new_observation)\n",
    "            new_observation = np.expand_dims(new_observation, axis=2)\n",
    "\n",
    "            # tore transition (φ_t, a_t, r_t, φ_t+1) in D (experience decay collection)\n",
    "            next_state = np.append(self.state[:, :, 1:], new_observation, axis=2)\n",
    "            self.exp_replay_list.append([self.state, self.action, reward, next_state, done])\n",
    "\n",
    "            self.state = next_state\n",
    "\n",
    "            # only train if done observing\n",
    "            if len(self.exp_replay_list) > self.OBSERVATION_STEPS:\n",
    "                loss = self.train()\n",
    "                print \"Step: \", step, \"Action:\", self.get_action_name(self.action), \"Loss:\", loss\n",
    "        \n",
    "        # pdb.set_trace()\n",
    "\n",
    "        if done:\n",
    "            self.reset_env()\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First state: (84, 84, 4)\n",
      "Epsilon: 0.99999\n",
      "Epsilon: 0.99995\n",
      "Epsilon: 0.99991\n",
      "Epsilon: 0.99987\n",
      "Epsilon: 0.99983\n",
      "Epsilon: 0.99979\n",
      "Epsilon: 0.99975\n",
      "Epsilon: 0.99971\n",
      "Epsilon: 0.99967\n",
      "Epsilon: 0.99963\n",
      "Epsilon: 0.99959\n",
      "Epsilon: 0.99955\n",
      "Epsilon: 0.99951\n",
      "Epsilon: 0.99947\n",
      "Epsilon: 0.99943\n",
      "Epsilon: 0.99939\n",
      "Epsilon: 0.99935\n",
      "Epsilon: 0.99931\n",
      "Epsilon: 0.99927\n",
      "Epsilon: 0.99923\n",
      "Epsilon: 0.99919\n",
      "Epsilon: 0.99915\n",
      "Epsilon: 0.99911\n",
      "Epsilon: 0.99907\n",
      "Epsilon: 0.99903\n",
      "Epsilon: 0.99899\n",
      "Epsilon: 0.99895\n",
      "Epsilon: 0.99891\n",
      "Epsilon: 0.99887\n",
      "Epsilon: 0.99883\n",
      "Epsilon: 0.99879\n",
      "Epsilon: 0.99875\n",
      "Epsilon: 0.99871\n",
      "Epsilon: 0.99867\n",
      "Epsilon: 0.99863\n",
      "Epsilon: 0.99859\n",
      "Epsilon: 0.99855\n",
      "Epsilon: 0.99851\n",
      "Epsilon: 0.99847\n",
      "Epsilon: 0.99843\n",
      "Epsilon: 0.99839\n",
      "Epsilon: 0.99835\n",
      "Epsilon: 0.99831\n",
      "Epsilon: 0.99827\n",
      "Epsilon: 0.99823\n",
      "Epsilon: 0.99819\n",
      "Epsilon: 0.99815\n",
      "Epsilon: 0.99811\n",
      "Epsilon: 0.99807\n",
      "Epsilon: 0.99803\n",
      "Epsilon: 0.99799\n",
      "Epsilon: 0.99795\n",
      "Epsilon: 0.99791\n",
      "Epsilon: 0.99787\n",
      "Epsilon: 0.99783\n",
      "Epsilon: 0.99779\n",
      "Epsilon: 0.99775\n",
      "Epsilon: 0.99771\n",
      "Epsilon: 0.99767\n",
      "Epsilon: 0.99763\n",
      "Epsilon: 0.99759\n",
      "Epsilon: 0.99755\n",
      "Epsilon: 0.99751\n",
      "Epsilon: 0.99747\n",
      "Epsilon: 0.99743\n",
      "Epsilon: 0.99739\n",
      "Epsilon: 0.99735\n",
      "Epsilon: 0.99731\n",
      "Epsilon: 0.99727\n",
      "Epsilon: 0.99723\n",
      "Epsilon: 0.99719\n",
      "Epsilon: 0.99715\n",
      "Epsilon: 0.99711\n",
      "Epsilon: 0.99707\n",
      "Epsilon: 0.99703\n",
      "Epsilon: 0.99699\n",
      "Epsilon: 0.99695\n",
      "Epsilon: 0.99691\n",
      "Epsilon: 0.99687\n",
      "Epsilon: 0.99683\n",
      "Epsilon: 0.99679\n",
      "Epsilon: 0.99675\n",
      "Epsilon: 0.99671\n",
      "Epsilon: 0.99667\n",
      "Epsilon: 0.99663\n",
      "Epsilon: 0.99659\n",
      "Epsilon: 0.99655\n",
      "Epsilon: 0.99651\n",
      "Epsilon: 0.99647\n",
      "Epsilon: 0.99643\n",
      "Epsilon: 0.99639\n",
      "Epsilon: 0.99635\n",
      "Epsilon: 0.99631\n",
      "Epsilon: 0.99627\n",
      "Epsilon: 0.99623\n",
      "Epsilon: 0.99619\n",
      "Epsilon: 0.99615\n",
      "Epsilon: 0.99611\n",
      "Epsilon: 0.99607\n",
      "Epsilon: 0.99603\n",
      "Epsilon: 0.99599\n",
      "Epsilon: 0.99595\n",
      "Epsilon: 0.99591\n",
      "Epsilon: 0.99587\n",
      "Epsilon: 0.99583\n",
      "Epsilon: 0.99579\n",
      "Epsilon: 0.99575\n",
      "Epsilon: 0.99571\n",
      "Epsilon: 0.99567\n",
      "Epsilon: 0.99563\n",
      "Epsilon: 0.99559\n",
      "Epsilon: 0.99555\n",
      "Epsilon: 0.99551\n",
      "Epsilon: 0.99547\n",
      "Epsilon: 0.99543\n",
      "Epsilon: 0.99539\n",
      "Epsilon: 0.99535\n",
      "Epsilon: 0.99531\n",
      "Epsilon: 0.99527\n",
      "Epsilon: 0.99523\n",
      "Epsilon: 0.99519\n",
      "Epsilon: 0.99515\n",
      "Epsilon: 0.99511\n",
      "Epsilon: 0.99507\n",
      "Epsilon: 0.99503\n",
      "Epsilon: 0.99499\n",
      "Epsilon: 0.99495\n",
      "Epsilon: 0.99491\n",
      "Epsilon: 0.99487\n",
      "Epsilon: 0.99483\n",
      "Epsilon: 0.99479\n",
      "Epsilon: 0.99475\n",
      "Epsilon: 0.99471\n",
      "Epsilon: 0.99467\n",
      "Epsilon: 0.99463\n",
      "Epsilon: 0.99459\n",
      "Epsilon: 0.99455\n",
      "Epsilon: 0.99451\n",
      "Epsilon: 0.99447\n",
      "Epsilon: 0.99443\n",
      "Epsilon: 0.99439\n",
      "Epsilon: 0.99435\n",
      "Epsilon: 0.99431\n",
      "Epsilon: 0.99427\n",
      "Epsilon: 0.99423\n",
      "Epsilon: 0.99419\n",
      "Epsilon: 0.99415\n",
      "Epsilon: 0.99411\n",
      "Epsilon: 0.99407\n",
      "Epsilon: 0.99403\n",
      "Epsilon: 0.99399\n",
      "Epsilon: 0.99395\n",
      "Epsilon: 0.99391\n",
      "Epsilon: 0.99387\n",
      "Epsilon: 0.99383\n",
      "Epsilon: 0.99379\n",
      "Epsilon: 0.99375\n",
      "Epsilon: 0.99371\n",
      "Epsilon: 0.99367\n",
      "Epsilon: 0.99363\n",
      "Epsilon: 0.99359\n",
      "Epsilon: 0.99355\n",
      "Epsilon: 0.99351\n",
      "Epsilon: 0.99347\n",
      "Epsilon: 0.99343\n",
      "Epsilon: 0.99339\n",
      "Epsilon: 0.99335\n",
      "Epsilon: 0.99331\n",
      "Epsilon: 0.99327\n",
      "Epsilon: 0.99323\n",
      "Epsilon: 0.99319\n",
      "Epsilon: 0.99315\n",
      "Epsilon: 0.99311\n",
      "Epsilon: 0.99307\n",
      "Epsilon: 0.99303\n",
      "Epsilon: 0.99299\n",
      "Epsilon: 0.99295\n",
      "Epsilon: 0.99291\n",
      "Epsilon: 0.99287\n",
      "Epsilon: 0.99283\n",
      "Epsilon: 0.99279\n",
      "Epsilon: 0.99275\n",
      "Epsilon: 0.99271\n",
      "Epsilon: 0.99267\n",
      "Epsilon: 0.99263\n",
      "Epsilon: 0.99259\n",
      "Epsilon: 0.99255\n",
      "Epsilon: 0.99251\n",
      "Epsilon: 0.99247\n",
      "Epsilon: 0.99243\n",
      "Epsilon: 0.99239\n",
      "Epsilon: 0.99235\n",
      "Epsilon: 0.99231\n",
      "Epsilon: 0.99227\n",
      "Epsilon: 0.99223\n",
      "Epsilon: 0.99219\n",
      "Epsilon: 0.99215\n",
      "Epsilon: 0.99211\n",
      "Epsilon: 0.99207\n",
      "Epsilon: 0.99203\n",
      "Epsilon: 0.99199\n",
      "Epsilon: 0.99195\n",
      "Epsilon: 0.99191\n",
      "Epsilon: 0.99187\n",
      "Epsilon: 0.99183\n",
      "Epsilon: 0.99179\n",
      "Epsilon: 0.99175\n",
      "Epsilon: 0.99171\n",
      "Epsilon: 0.99167\n",
      "Epsilon: 0.99163\n",
      "Epsilon: 0.99159\n",
      "Epsilon: 0.99155\n",
      "Epsilon: 0.99151\n",
      "Epsilon: 0.99147\n",
      "Epsilon: 0.99143\n",
      "Epsilon: 0.99139\n",
      "Epsilon: 0.99135\n",
      "Epsilon: 0.99131\n",
      "Epsilon: 0.99127\n",
      "Epsilon: 0.99123\n",
      "Epsilon: 0.99119\n",
      "Epsilon: 0.99115\n",
      "Epsilon: 0.99111\n",
      "Epsilon: 0.99107\n",
      "Epsilon: 0.99103\n",
      "Epsilon: 0.99099\n",
      "Epsilon: 0.99095\n",
      "Epsilon: 0.99091\n",
      "Episode finished after 911 timesteps\n",
      "Epsilon: 0.99087\n",
      "Epsilon: 0.99083\n",
      "Epsilon: 0.99079\n",
      "Epsilon: 0.99075\n",
      "Epsilon: 0.99071\n",
      "Epsilon: 0.99067\n",
      "Epsilon: 0.99063\n",
      "Epsilon: 0.99059\n",
      "Epsilon: 0.99055\n",
      "Epsilon: 0.99051\n",
      "Epsilon: 0.99047\n",
      "Epsilon: 0.99043\n",
      "Epsilon: 0.99039\n",
      "Epsilon: 0.99035\n",
      "Epsilon: 0.99031\n",
      "Epsilon: 0.99027\n",
      "Epsilon: 0.99023\n",
      "Epsilon: 0.99019\n",
      "Epsilon: 0.99015\n",
      "Epsilon: 0.99011\n",
      "Epsilon: 0.99007\n",
      "Epsilon: 0.99003\n",
      "Epsilon: 0.98999\n",
      "Epsilon: 0.98995\n",
      "Epsilon: 0.98991\n",
      "Epsilon: 0.98987\n",
      "Epsilon: 0.98983\n",
      "Epsilon: 0.98979\n",
      "Epsilon: 0.98975\n",
      "Epsilon: 0.98971\n",
      "Epsilon: 0.98967\n",
      "Epsilon: 0.98963\n",
      "Epsilon: 0.98959\n",
      "Epsilon: 0.98955\n",
      "Epsilon: 0.98951\n",
      "Epsilon: 0.98947\n",
      "Epsilon: 0.98943\n",
      "Epsilon: 0.98939\n",
      "Epsilon: 0.98935\n",
      "Epsilon: 0.98931\n",
      "Epsilon: 0.98927\n",
      "Epsilon: 0.98923\n",
      "Epsilon: 0.98919\n",
      "Epsilon: 0.98915\n",
      "Epsilon: 0.98911\n",
      "Epsilon: 0.98907\n",
      "Epsilon: 0.98903\n",
      "Epsilon: 0.98899\n",
      "Epsilon: 0.98895\n",
      "Epsilon: 0.98891\n",
      "Epsilon: 0.98887\n",
      "Epsilon: 0.98883\n",
      "Epsilon: 0.98879\n",
      "Epsilon: 0.98875\n",
      "Epsilon: 0.98871\n",
      "Epsilon: 0.98867\n",
      "Epsilon: 0.98863\n",
      "Epsilon: 0.98859\n",
      "Epsilon: 0.98855\n",
      "Epsilon: 0.98851\n",
      "Epsilon: 0.98847\n",
      "Epsilon: 0.98843\n",
      "Epsilon: 0.98839\n",
      "Epsilon: 0.98835\n",
      "Epsilon: 0.98831\n",
      "Epsilon: 0.98827\n",
      "Epsilon: 0.98823\n",
      "Epsilon: 0.98819\n",
      "Epsilon: 0.98815\n",
      "Epsilon: 0.98811\n",
      "Epsilon: 0.98807\n",
      "Epsilon: 0.98803\n",
      "Epsilon: 0.98799\n",
      "Epsilon: 0.98795\n",
      "Epsilon: 0.98791\n",
      "Epsilon: 0.98787\n",
      "Epsilon: 0.98783\n",
      "Epsilon: 0.98779\n",
      "Epsilon: 0.98775\n",
      "Epsilon: 0.98771\n",
      "Epsilon: 0.98767\n",
      "Epsilon: 0.98763\n",
      "Epsilon: 0.98759\n",
      "Epsilon: 0.98755\n",
      "Epsilon: 0.98751\n",
      "Epsilon: 0.98747\n",
      "Epsilon: 0.98743\n",
      "Epsilon: 0.98739\n",
      "Epsilon: 0.98735\n",
      "Epsilon: 0.98731\n",
      "Epsilon: 0.98727\n",
      "Epsilon: 0.98723\n",
      "Epsilon: 0.98719\n",
      "Epsilon: 0.98715\n",
      "Epsilon: 0.98711\n",
      "Epsilon: 0.98707\n",
      "Epsilon: 0.98703\n",
      "Epsilon: 0.98699\n",
      "Epsilon: 0.98695\n",
      "Epsilon: 0.98691\n",
      "Epsilon: 0.98687\n",
      "Epsilon: 0.98683\n",
      "Epsilon: 0.98679\n",
      "Epsilon: 0.98675\n",
      "Epsilon: 0.98671\n",
      "Epsilon: 0.98667\n",
      "Epsilon: 0.98663\n",
      "Epsilon: 0.98659\n",
      "Epsilon: 0.98655\n",
      "Epsilon: 0.98651\n",
      "Epsilon: 0.98647\n",
      "Epsilon: 0.98643\n",
      "Epsilon: 0.98639\n",
      "Epsilon: 0.98635\n",
      "Epsilon: 0.98631\n",
      "Epsilon: 0.98627\n",
      "Epsilon: 0.98623\n",
      "Epsilon: 0.98619\n",
      "Epsilon: 0.98615\n",
      "Epsilon: 0.98611\n",
      "Epsilon: 0.98607\n",
      "Epsilon: 0.98603\n",
      "Epsilon: 0.98599\n",
      "Epsilon: 0.98595\n",
      "Epsilon: 0.98591\n",
      "Epsilon: 0.98587\n",
      "Epsilon: 0.98583\n",
      "Epsilon: 0.98579\n",
      "Epsilon: 0.98575\n",
      "Epsilon: 0.98571\n",
      "Epsilon: 0.98567\n",
      "Epsilon: 0.98563\n",
      "Epsilon: 0.98559\n",
      "Epsilon: 0.98555\n",
      "Epsilon: 0.98551\n",
      "Epsilon: 0.98547\n",
      "Epsilon: 0.98543\n",
      "Epsilon: 0.98539\n",
      "Epsilon: 0.98535\n",
      "Epsilon: 0.98531\n",
      "Epsilon: 0.98527\n",
      "Epsilon: 0.98523\n",
      "Epsilon: 0.98519\n",
      "Epsilon: 0.98515\n",
      "Epsilon: 0.98511\n",
      "Epsilon: 0.98507\n",
      "Epsilon: 0.98503\n",
      "Epsilon: 0.98499\n",
      "Epsilon: 0.98495\n",
      "Epsilon: 0.98491\n",
      "Epsilon: 0.98487\n",
      "Epsilon: 0.98483\n",
      "Epsilon: 0.98479\n",
      "Epsilon: 0.98475\n",
      "Epsilon: 0.98471\n",
      "Epsilon: 0.98467\n",
      "Epsilon: 0.98463\n",
      "Epsilon: 0.98459\n",
      "Epsilon: 0.98455\n",
      "Epsilon: 0.98451\n",
      "Epsilon: 0.98447\n",
      "Epsilon: 0.98443\n",
      "Epsilon: 0.98439\n",
      "Epsilon: 0.98435\n",
      "Epsilon: 0.98431\n",
      "Epsilon: 0.98427\n",
      "Epsilon: 0.98423\n",
      "Epsilon: 0.98419\n",
      "Epsilon: 0.98415\n",
      "Epsilon: 0.98411\n",
      "Epsilon: 0.98407\n",
      "Epsilon: 0.98403\n",
      "Epsilon: 0.98399\n",
      "Epsilon: 0.98395\n",
      "Epsilon: 0.98391\n",
      "Epsilon: 0.98387\n",
      "Epsilon: 0.98383\n",
      "Epsilon: 0.98379\n",
      "Epsilon: 0.98375\n",
      "Epsilon: 0.98371\n",
      "Epsilon: 0.98367\n",
      "Epsilon: 0.98363\n",
      "Epsilon: 0.98359\n",
      "Epsilon: 0.98355\n",
      "Epsilon: 0.98351\n",
      "Epsilon: 0.98347\n",
      "Epsilon: 0.98343\n",
      "Epsilon: 0.98339\n",
      "Epsilon: 0.98335\n",
      "Epsilon: 0.98331\n",
      "Epsilon: 0.98327\n",
      "Epsilon: 0.98323\n",
      "Epsilon: 0.98319\n",
      "Epsilon: 0.98315\n",
      "Episode finished after 1686 timesteps\n",
      "Epsilon: 0.98311\n",
      "Epsilon: 0.98307\n",
      "Epsilon: 0.98303\n",
      "Epsilon: 0.98299\n",
      "Epsilon: 0.98295\n",
      "Epsilon: 0.98291\n",
      "Epsilon: 0.98287\n",
      "Epsilon: 0.98283\n",
      "Epsilon: 0.98279\n",
      "Epsilon: 0.98275\n",
      "Epsilon: 0.98271\n",
      "Epsilon: 0.98267\n",
      "Epsilon: 0.98263\n",
      "Epsilon: 0.98259\n",
      "Epsilon: 0.98255\n",
      "Epsilon: 0.98251\n",
      "Epsilon: 0.98247\n",
      "Epsilon: 0.98243\n",
      "Epsilon: 0.98239\n",
      "Epsilon: 0.98235\n",
      "Epsilon: 0.98231\n",
      "Epsilon: 0.98227\n",
      "Epsilon: 0.98223\n",
      "Epsilon: 0.98219\n",
      "Epsilon: 0.98215\n",
      "Epsilon: 0.98211\n",
      "Epsilon: 0.98207\n",
      "Epsilon: 0.98203\n",
      "Epsilon: 0.98199\n",
      "Epsilon: 0.98195\n",
      "Epsilon: 0.98191\n",
      "Epsilon: 0.98187\n",
      "Epsilon: 0.98183\n",
      "Epsilon: 0.98179\n",
      "Epsilon: 0.98175\n",
      "Epsilon: 0.98171\n",
      "Epsilon: 0.98167\n",
      "Epsilon: 0.98163\n",
      "Epsilon: 0.98159\n",
      "Epsilon: 0.98155\n",
      "Epsilon: 0.98151\n",
      "Epsilon: 0.98147\n",
      "Epsilon: 0.98143\n",
      "Epsilon: 0.98139\n",
      "Epsilon: 0.98135\n",
      "Epsilon: 0.98131\n",
      "Epsilon: 0.98127\n",
      "Epsilon: 0.98123\n",
      "Epsilon: 0.98119\n",
      "Epsilon: 0.98115\n",
      "Epsilon: 0.98111\n",
      "Epsilon: 0.98107\n",
      "Epsilon: 0.98103\n",
      "Epsilon: 0.98099\n",
      "Epsilon: 0.98095\n",
      "Epsilon: 0.98091\n",
      "Epsilon: 0.98087\n",
      "Epsilon: 0.98083\n",
      "Epsilon: 0.98079\n",
      "Epsilon: 0.98075\n",
      "Epsilon: 0.98071\n",
      "Epsilon: 0.98067\n",
      "Epsilon: 0.98063\n",
      "Epsilon: 0.98059\n",
      "Epsilon: 0.98055\n",
      "Epsilon: 0.98051\n",
      "Epsilon: 0.98047\n",
      "Epsilon: 0.98043\n",
      "Epsilon: 0.98039\n",
      "Epsilon: 0.98035\n",
      "Epsilon: 0.98031\n",
      "Epsilon: 0.98027\n",
      "Epsilon: 0.98023\n",
      "Epsilon: 0.98019\n",
      "Epsilon: 0.98015\n",
      "Epsilon: 0.98011\n",
      "Epsilon: 0.98007\n",
      "Epsilon: 0.98003\n",
      "Epsilon: 0.97999\n",
      "Step:  2000 Action: DOWNRIGHT Loss: 3.54957\n",
      "Epsilon: 0.97995\n",
      "Step:  2004 Action: NOOP Loss: 3.25896\n",
      "Epsilon: 0.97991\n",
      "Step:  2008 Action: DOWNRIGHT Loss: 3.37497\n",
      "Epsilon: 0.97987\n",
      "Step:  2012 Action: DOWNLEFT Loss: 0.457836\n",
      "Epsilon: 0.97983\n",
      "Step:  2016 Action: UPRIGHT Loss: 3.37285\n",
      "Epsilon: 0.97979\n",
      "Step:  2020 Action: RIGHT Loss: 0.353898\n",
      "Epsilon: 0.97975\n",
      "Step:  2024 Action: UPLEFT Loss: 0.299256\n",
      "Epsilon: 0.97971\n",
      "Step:  2028 Action: UPRIGHT Loss: 4.03579\n",
      "Epsilon: 0.97967\n",
      "Step:  2032 Action: UPLEFT Loss: 0.311896\n",
      "Epsilon: 0.97963\n",
      "Step:  2036 Action: UPRIGHT Loss: 3.44242\n",
      "Epsilon: 0.97959\n",
      "Step:  2040 Action: LEFT Loss: 3.96924\n",
      "Epsilon: 0.97955\n",
      "Step:  2044 Action: LEFT Loss: 3.63012\n",
      "Epsilon: 0.97951\n",
      "Step:  2048 Action: NOOP Loss: 3.40421\n",
      "Epsilon: 0.97947\n",
      "Step:  2052 Action: LEFT Loss: 3.70179\n",
      "Epsilon: 0.97943\n",
      "Step:  2056 Action: DOWN Loss: 6.95974\n",
      "Epsilon: 0.97939\n",
      "Step:  2060 Action: UP Loss: 10.2232\n",
      "Epsilon: 0.97935\n",
      "Step:  2064 Action: NOOP Loss: 9.93721\n",
      "Epsilon: 0.97931\n",
      "Step:  2068 Action: LEFT Loss: 3.32732\n",
      "Epsilon: 0.97927\n",
      "Step:  2072 Action: LEFT Loss: 0.241452\n",
      "Epsilon: 0.97923\n",
      "Step:  2076 Action: DOWN Loss: 3.67655\n",
      "Epsilon: 0.97919\n",
      "Step:  2080 Action: UPLEFT Loss: 3.59124\n",
      "Epsilon: 0.97915\n",
      "Step:  2084 Action: UPRIGHT Loss: 3.33218\n",
      "Epsilon: 0.97911\n",
      "Step:  2088 Action: DOWNRIGHT Loss: 0.291429\n",
      "Epsilon: 0.97907\n",
      "Step:  2092 Action: UP Loss: 10.5081\n",
      "Epsilon: 0.97903\n",
      "Step:  2096 Action: UPRIGHT Loss: 0.485493\n",
      "Epsilon: 0.97899\n",
      "Step:  2100 Action: DOWNRIGHT Loss: 7.30073\n",
      "Epsilon: 0.97895\n",
      "Step:  2104 Action: UPLEFT Loss: 3.32598\n",
      "Epsilon: 0.97891\n",
      "Step:  2108 Action: UPLEFT Loss: 7.32093\n",
      "Epsilon: 0.97887\n",
      "Step:  2112 Action: UPLEFT Loss: 0.480174\n",
      "Epsilon: 0.97883\n",
      "Step:  2116 Action: UP Loss: 10.2284\n",
      "Epsilon: 0.97879\n",
      "Step:  2120 Action: DOWNLEFT Loss: 0.413575\n",
      "Epsilon: 0.97875\n",
      "Step:  2124 Action: DOWN Loss: 3.31747\n",
      "Epsilon: 0.97871\n",
      "Step:  2128 Action: RIGHT Loss: 4.00715\n",
      "Epsilon: 0.97867\n",
      "Step:  2132 Action: NOOP Loss: 3.92706\n",
      "Epsilon: 0.97863\n",
      "Step:  2136 Action: RIGHT Loss: 3.11023\n",
      "Epsilon: 0.97859\n",
      "Step:  2140 Action: DOWNLEFT Loss: 7.30237\n",
      "Epsilon: 0.97855\n",
      "Step:  2144 Action: LEFT Loss: 0.500014\n",
      "Epsilon: 0.97851\n",
      "Step:  2148 Action: DOWNRIGHT Loss: 7.40038\n",
      "Epsilon: 0.97847\n",
      "Step:  2152 Action: RIGHT Loss: 0.557339\n",
      "Epsilon: 0.97843\n",
      "Step:  2156 Action: UP Loss: 7.14313\n",
      "Epsilon: 0.97839\n",
      "Step:  2160 Action: DOWN Loss: 7.57489\n",
      "Epsilon: 0.97835\n",
      "Step:  2164 Action: DOWN Loss: 7.02703\n",
      "Epsilon: 0.97831\n",
      "Step:  2168 Action: DOWN Loss: 7.74008\n",
      "Epsilon: 0.97827\n",
      "Step:  2172 Action: RIGHT Loss: 6.81049\n",
      "Epsilon: 0.97823\n",
      "Step:  2176 Action: DOWN Loss: 6.96039\n",
      "Epsilon: 0.97819\n",
      "Step:  2180 Action: DOWNLEFT Loss: 4.60355\n",
      "Epsilon: 0.97815\n",
      "Step:  2184 Action: DOWNRIGHT Loss: 0.550193\n",
      "Epsilon: 0.97811\n",
      "Step:  2188 Action: DOWNLEFT Loss: 0.619456\n",
      "Epsilon: 0.97807\n",
      "Step:  2192 Action: UPRIGHT Loss: 10.3051\n",
      "Epsilon: 0.97803\n",
      "Step:  2196 Action: UP Loss: 0.5661\n",
      "Epsilon: 0.97799\n",
      "Step:  2200 Action: DOWNLEFT Loss: 7.27487\n",
      "Epsilon: 0.97795\n",
      "Step:  2204 Action: DOWNLEFT Loss: 11.2936\n",
      "Epsilon: 0.97791\n",
      "Step:  2208 Action: UPLEFT Loss: 0.641743\n",
      "Epsilon: 0.97787\n",
      "Step:  2212 Action: NOOP Loss: 10.1141\n",
      "Epsilon: 0.97783\n",
      "Step:  2216 Action: NOOP Loss: 10.0046\n",
      "Epsilon: 0.97779\n",
      "Step:  2220 Action: RIGHT Loss: 7.39459\n",
      "Epsilon: 0.97775\n",
      "Step:  2224 Action: LEFT Loss: 6.18249\n",
      "Epsilon: 0.97771\n",
      "Step:  2228 Action: RIGHT Loss: 7.28109\n",
      "Epsilon: 0.97767\n",
      "Step:  2232 Action: UP Loss: 0.951993\n",
      "Epsilon: 0.97763\n",
      "Step:  2236 Action: UPRIGHT Loss: 4.39243\n",
      "Epsilon: 0.97759\n",
      "Step:  2240 Action: UPLEFT Loss: 0.919898\n",
      "Epsilon: 0.97755\n",
      "Step:  2244 Action: UP Loss: 0.770347\n",
      "Epsilon: 0.97751\n",
      "Step:  2248 Action: DOWNLEFT Loss: 0.824473\n",
      "Epsilon: 0.97747\n",
      "Step:  2252 Action: DOWNRIGHT Loss: 4.06218\n",
      "Epsilon: 0.97743\n",
      "Step:  2256 Action: DOWNRIGHT Loss: 13.0764\n",
      "Epsilon: 0.97739\n",
      "Step:  2260 Action: LEFT Loss: 7.50248\n",
      "Epsilon: 0.97735\n",
      "Step:  2264 Action: DOWN Loss: 3.79006\n",
      "Epsilon: 0.97731\n",
      "Step:  2268 Action: UP Loss: 3.65647\n",
      "Epsilon: 0.97727\n",
      "Step:  2272 Action: UPLEFT Loss: 0.678475\n",
      "Epsilon: 0.97723\n",
      "Step:  2276 Action: UPLEFT Loss: 5.01076\n",
      "Epsilon: 0.97719\n",
      "Step:  2280 Action: DOWN Loss: 17.5315\n",
      "Epsilon: 0.97715\n",
      "Step:  2284 Action: UP Loss: 10.5145\n",
      "Epsilon: 0.97711\n",
      "Step:  2288 Action: RIGHT Loss: 7.62668\n",
      "Epsilon: 0.97707\n",
      "Step:  2292 Action: NOOP Loss: 0.783528\n",
      "Epsilon: 0.97703\n",
      "Step:  2296 Action: NOOP Loss: 0.991207\n",
      "Epsilon: 0.97699\n",
      "Step:  2300 Action: DOWNRIGHT Loss: 3.86669\n",
      "Epsilon: 0.97695\n",
      "Step:  2304 Action: UPLEFT Loss: 0.956581\n",
      "Epsilon: 0.97691\n",
      "Step:  2308 Action: RIGHT Loss: 12.3771\n",
      "Epsilon: 0.97687\n",
      "Step:  2312 Action: DOWNLEFT Loss: 1.15208\n",
      "Epsilon: 0.97683\n",
      "Step:  2316 Action: DOWNLEFT Loss: 4.50981\n",
      "Epsilon: 0.97679\n",
      "Step:  2320 Action: RIGHT Loss: 7.68833\n",
      "Epsilon: 0.97675\n",
      "Step:  2324 Action: UP Loss: 11.3853\n",
      "Epsilon: 0.97671\n",
      "Step:  2328 Action: RIGHT Loss: 11.0062\n",
      "Epsilon: 0.97667\n",
      "Step:  2332 Action: DOWNRIGHT Loss: 1.21612\n",
      "Epsilon: 0.97663\n",
      "Step:  2336 Action: UPLEFT Loss: 3.57599\n",
      "Epsilon: 0.97659\n",
      "Step:  2340 Action: UPLEFT Loss: 3.96078\n",
      "Epsilon: 0.97655\n",
      "Step:  2344 Action: RIGHT Loss: 6.97029\n",
      "Epsilon: 0.97651\n",
      "Step:  2348 Action: UP Loss: 4.67481\n",
      "Epsilon: 0.97647\n",
      "Step:  2352 Action: UPRIGHT Loss: 4.68566\n",
      "Epsilon: 0.97643\n",
      "Step:  2356 Action: UPLEFT Loss: 11.2614\n",
      "Epsilon: 0.97639\n",
      "Step:  2360 Action: LEFT Loss: 7.23543\n",
      "Epsilon: 0.97635\n",
      "Step:  2364 Action: DOWN Loss: 4.69786\n",
      "Epsilon: 0.97631\n",
      "Step:  2368 Action: RIGHT Loss: 1.25863\n",
      "Epsilon: 0.97627\n",
      "Step:  2372 Action: UP Loss: 7.43911\n",
      "Epsilon: 0.97623\n",
      "Step:  2376 Action: UPLEFT Loss: 3.95548\n",
      "Epsilon: 0.97619\n",
      "Step:  2380 Action: NOOP Loss: 4.46777\n",
      "Epsilon: 0.97615\n",
      "Step:  2384 Action: RIGHT Loss: 7.80708\n",
      "Epsilon: 0.97611\n",
      "Step:  2388 Action: UPLEFT Loss: 1.2397\n",
      "Epsilon: 0.97607\n",
      "Step:  2392 Action: LEFT Loss: 6.9466\n",
      "Episode finished after 2395 timesteps\n",
      "Epsilon: 0.97603\n",
      "Step:  2396 Action: DOWNRIGHT Loss: 4.2662\n",
      "Epsilon: 0.97599\n",
      "Step:  2400 Action: UP Loss: 0.925854\n",
      "Epsilon: 0.97595\n",
      "Step:  2404 Action: UPRIGHT Loss: 1.53256\n",
      "Epsilon: 0.97591\n",
      "Step:  2408 Action: RIGHT Loss: 1.33896\n",
      "Epsilon: 0.97587\n",
      "Step:  2412 Action: UPLEFT Loss: 4.13934\n",
      "Epsilon: 0.97583\n",
      "Step:  2416 Action: UPLEFT Loss: 1.06489\n",
      "Epsilon: 0.97579\n",
      "Step:  2420 Action: UP Loss: 1.19092\n",
      "Epsilon: 0.97575\n",
      "Step:  2424 Action: NOOP Loss: 6.47941\n",
      "Epsilon: 0.97571\n",
      "Step:  2428 Action: UP Loss: 5.80816\n",
      "Epsilon: 0.97567\n",
      "Step:  2432 Action: LEFT Loss: 10.7513\n",
      "Epsilon: 0.97563\n",
      "Step:  2436 Action: LEFT Loss: 1.54648\n",
      "Epsilon: 0.97559\n",
      "Step:  2440 Action: UP Loss: 9.55718\n",
      "Epsilon: 0.97555\n",
      "Step:  2444 Action: LEFT Loss: 4.75957\n",
      "Epsilon: 0.97551\n",
      "Step:  2448 Action: DOWN Loss: 3.54837\n",
      "Epsilon: 0.97547\n",
      "Step:  2452 Action: LEFT Loss: 1.43746\n",
      "Epsilon: 0.97543\n",
      "Step:  2456 Action: UPRIGHT Loss: 4.55723\n",
      "Epsilon: 0.97539\n",
      "Step:  2460 Action: UPLEFT Loss: 9.51592\n",
      "Epsilon: 0.97535\n",
      "Step:  2464 Action: DOWNLEFT Loss: 10.3001\n",
      "Epsilon: 0.97531\n",
      "Step:  2468 Action: UPRIGHT Loss: 9.0803\n",
      "Epsilon: 0.97527\n",
      "Step:  2472 Action: UPRIGHT Loss: 1.32104\n",
      "Epsilon: 0.97523\n",
      "Step:  2476 Action: DOWNLEFT Loss: 4.42655\n",
      "Epsilon: 0.97519\n",
      "Step:  2480 Action: DOWN Loss: 5.45017\n",
      "Epsilon: 0.97515\n",
      "Step:  2484 Action: UPRIGHT Loss: 1.95943\n",
      "Epsilon: 0.97511\n",
      "Step:  2488 Action: NOOP Loss: 3.55992\n",
      "Epsilon: 0.97507\n",
      "Step:  2492 Action: LEFT Loss: 5.52884\n",
      "Epsilon: 0.97503\n",
      "Step:  2496 Action: UP Loss: 13.6907\n",
      "Epsilon: 0.97499\n",
      "Step:  2500 Action: UPLEFT Loss: 7.8707\n",
      "Epsilon: 0.97495\n",
      "Step:  2504 Action: DOWNLEFT Loss: 1.27592\n",
      "Epsilon: 0.97491\n",
      "Step:  2508 Action: UPLEFT Loss: 1.47075\n",
      "Epsilon: 0.97487\n",
      "Step:  2512 Action: LEFT Loss: 9.70684\n",
      "Epsilon: 0.97483\n",
      "Step:  2516 Action: DOWN Loss: 4.70507\n",
      "Epsilon: 0.97479\n",
      "Step:  2520 Action: UPRIGHT Loss: 12.6384\n",
      "Epsilon: 0.97475\n",
      "Step:  2524 Action: DOWNLEFT Loss: 1.70897\n",
      "Epsilon: 0.97471\n",
      "Step:  2528 Action: RIGHT Loss: 1.70345\n",
      "Epsilon: 0.97467\n",
      "Step:  2532 Action: LEFT Loss: 7.36503\n",
      "Epsilon: 0.97463\n",
      "Step:  2536 Action: RIGHT Loss: 4.19174\n",
      "Epsilon: 0.97459\n",
      "Step:  2540 Action: UP Loss: 5.20557\n",
      "Epsilon: 0.97455\n",
      "Step:  2544 Action: UP Loss: 12.7594\n",
      "Epsilon: 0.97451\n",
      "Step:  2548 Action: DOWNLEFT Loss: 8.80072\n",
      "Epsilon: 0.97447\n",
      "Step:  2552 Action: UPLEFT Loss: 1.60229\n",
      "Epsilon: 0.97443\n",
      "Step:  2556 Action: LEFT Loss: 1.50627\n",
      "Epsilon: 0.97439\n",
      "Step:  2560 Action: RIGHT Loss: 11.8337\n",
      "Epsilon: 0.97435\n",
      "Step:  2564 Action: RIGHT Loss: 5.50942\n",
      "Epsilon: 0.97431\n",
      "Step:  2568 Action: DOWN Loss: 9.92912\n",
      "Epsilon: 0.97427\n",
      "Step:  2572 Action: DOWNRIGHT Loss: 2.09408\n",
      "Epsilon: 0.97423\n",
      "Step:  2576 Action: RIGHT Loss: 1.90828\n",
      "Epsilon: 0.97419\n",
      "Step:  2580 Action: DOWN Loss: 7.72504\n",
      "Epsilon: 0.97415\n",
      "Step:  2584 Action: DOWN Loss: 9.87803\n",
      "Epsilon: 0.97411\n",
      "Step:  2588 Action: UP Loss: 3.95189\n",
      "Epsilon: 0.97407\n",
      "Step:  2592 Action: UPRIGHT Loss: 3.89512\n",
      "Epsilon: 0.97403\n",
      "Step:  2596 Action: LEFT Loss: 5.6129\n",
      "Epsilon: 0.97399\n",
      "Step:  2600 Action: LEFT Loss: 4.33808\n",
      "Epsilon: 0.97395\n",
      "Step:  2604 Action: DOWNRIGHT Loss: 6.82349\n",
      "Epsilon: 0.97391\n",
      "Step:  2608 Action: DOWN Loss: 7.00796\n",
      "Epsilon: 0.97387\n",
      "Step:  2612 Action: RIGHT Loss: 1.58661\n",
      "Epsilon: 0.97383\n",
      "Step:  2616 Action: NOOP Loss: 0.876153\n",
      "Epsilon: 0.97379\n",
      "Step:  2620 Action: RIGHT Loss: 6.88048\n",
      "Epsilon: 0.97375\n",
      "Step:  2624 Action: RIGHT Loss: 6.89771\n",
      "Epsilon: 0.97371\n",
      "Step:  2628 Action: UPLEFT Loss: 8.8233\n",
      "Epsilon: 0.97367\n",
      "Step:  2632 Action: DOWNLEFT Loss: 4.69643\n",
      "Epsilon: 0.97363\n",
      "Step:  2636 Action: UP Loss: 1.47349\n",
      "Epsilon: 0.97359\n",
      "Step:  2640 Action: UP Loss: 7.57677\n",
      "Epsilon: 0.97355\n",
      "Step:  2644 Action: UP Loss: 3.79972\n",
      "Epsilon: 0.97351\n",
      "Step:  2648 Action: NOOP Loss: 11.3726\n",
      "Epsilon: 0.97347\n",
      "Step:  2652 Action: UP Loss: 0.790317\n",
      "Epsilon: 0.97343\n",
      "Step:  2656 Action: UP Loss: 1.58012\n",
      "Epsilon: 0.97339\n",
      "Step:  2660 Action: DOWNRIGHT Loss: 7.72782\n",
      "Epsilon: 0.97335\n",
      "Step:  2664 Action: NOOP Loss: 2.34307\n",
      "Epsilon: 0.97331\n",
      "Step:  2668 Action: UPLEFT Loss: 8.80865\n",
      "Epsilon: 0.97327\n",
      "Step:  2672 Action: UPRIGHT Loss: 4.8814\n",
      "Epsilon: 0.97323\n",
      "Step:  2676 Action: DOWNLEFT Loss: 2.37954\n",
      "Epsilon: 0.97319\n",
      "Step:  2680 Action: UPRIGHT Loss: 7.57544\n",
      "Epsilon: 0.97315\n",
      "Step:  2684 Action: UPLEFT Loss: 9.6564\n",
      "Epsilon: 0.97311\n",
      "Step:  2688 Action: DOWNLEFT Loss: 5.75109\n",
      "Epsilon: 0.97307\n",
      "Step:  2692 Action: UP Loss: 4.78904\n",
      "Epsilon: 0.97303\n",
      "Step:  2696 Action: DOWN Loss: 2.437\n",
      "Epsilon: 0.97299\n",
      "Step:  2700 Action: UPRIGHT Loss: 12.4483\n",
      "Epsilon: 0.97295\n",
      "Step:  2704 Action: NOOP Loss: 5.57361\n",
      "Epsilon: 0.97291\n",
      "Step:  2708 Action: UPRIGHT Loss: 7.21806\n",
      "Epsilon: 0.97287\n",
      "Step:  2712 Action: UPLEFT Loss: 2.56401\n",
      "Epsilon: 0.97283\n",
      "Step:  2716 Action: UP Loss: 11.0669\n",
      "Epsilon: 0.97279\n",
      "Step:  2720 Action: UP Loss: 4.6548\n",
      "Epsilon: 0.97275\n",
      "Step:  2724 Action: LEFT Loss: 4.81306\n",
      "Epsilon: 0.97271\n",
      "Step:  2728 Action: UP Loss: 5.18053\n",
      "Epsilon: 0.97267\n",
      "Step:  2732 Action: UPLEFT Loss: 1.59386\n",
      "Epsilon: 0.97263\n",
      "Step:  2736 Action: NOOP Loss: 7.42735\n",
      "Epsilon: 0.97259\n",
      "Step:  2740 Action: DOWNRIGHT Loss: 4.36896\n",
      "Epsilon: 0.97255\n",
      "Step:  2744 Action: UPLEFT Loss: 2.25415\n",
      "Epsilon: 0.97251\n",
      "Step:  2748 Action: DOWN Loss: 11.0507\n",
      "Epsilon: 0.97247\n",
      "Step:  2752 Action: RIGHT Loss: 2.05222\n",
      "Epsilon: 0.97243\n",
      "Step:  2756 Action: LEFT Loss: 10.8515\n",
      "Epsilon: 0.97239\n",
      "Step:  2760 Action: UPLEFT Loss: 4.32781\n",
      "Epsilon: 0.97235\n",
      "Step:  2764 Action: UPLEFT Loss: 11.0762\n",
      "Epsilon: 0.97231\n",
      "Step:  2768 Action: RIGHT Loss: 2.85081\n",
      "Epsilon: 0.97227\n",
      "Step:  2772 Action: UP Loss: 9.15276\n",
      "Episode finished after 2774 timesteps\n",
      "Epsilon: 0.97223\n",
      "Step:  2776 Action: DOWNRIGHT Loss: 3.95557\n",
      "Epsilon: 0.97219\n",
      "Step:  2780 Action: DOWNLEFT Loss: 5.69759\n",
      "Epsilon: 0.97215\n",
      "Step:  2784 Action: DOWNLEFT Loss: 5.85814\n",
      "Epsilon: 0.97211\n",
      "Step:  2788 Action: DOWN Loss: 7.79852\n",
      "Epsilon: 0.97207\n",
      "Step:  2792 Action: RIGHT Loss: 5.94975\n",
      "Epsilon: 0.97203\n",
      "Step:  2796 Action: DOWNLEFT Loss: 5.39503\n",
      "Epsilon: 0.97199\n",
      "Step:  2800 Action: NOOP Loss: 6.34295\n",
      "Epsilon: 0.97195\n",
      "Step:  2804 Action: LEFT Loss: 7.16337\n",
      "Epsilon: 0.97191\n",
      "Step:  2808 Action: NOOP Loss: 6.80204\n",
      "Epsilon: 0.97187\n",
      "Step:  2812 Action: UPRIGHT Loss: 10.1206\n",
      "Epsilon: 0.97183\n",
      "Step:  2816 Action: DOWNRIGHT Loss: 5.33376\n",
      "Epsilon: 0.97179\n",
      "Step:  2820 Action: DOWNRIGHT Loss: 5.46398\n",
      "Epsilon: 0.97175\n",
      "Step:  2824 Action: DOWN Loss: 8.50725\n",
      "Epsilon: 0.97171\n",
      "Step:  2828 Action: DOWNLEFT Loss: 11.9786\n",
      "Epsilon: 0.97167\n",
      "Step:  2832 Action: RIGHT Loss: 6.09706\n",
      "Epsilon: 0.97163\n",
      "Step:  2836 Action: UPRIGHT Loss: 5.46429\n",
      "Epsilon: 0.97159\n",
      "Step:  2840 Action: UP Loss: 16.6118\n",
      "Epsilon: 0.97155\n",
      "Step:  2844 Action: DOWNRIGHT Loss: 9.6497\n",
      "Epsilon: 0.97151\n",
      "Step:  2848 Action: DOWNRIGHT Loss: 5.84766\n",
      "Epsilon: 0.97147\n",
      "Step:  2852 Action: UP Loss: 8.99408\n",
      "Epsilon: 0.97143\n",
      "Step:  2856 Action: UPRIGHT Loss: 17.1358\n",
      "Epsilon: 0.97139\n",
      "Step:  2860 Action: NOOP Loss: 10.2221\n",
      "Epsilon: 0.97135\n",
      "Step:  2864 Action: DOWNRIGHT Loss: 6.01778\n",
      "Epsilon: 0.97131\n",
      "Step:  2868 Action: DOWNLEFT Loss: 15.1692\n",
      "Epsilon: 0.97127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b3a20a38afac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDELAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5943ccf3104b>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# only train if done observing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_replay_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBSERVATION_STEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Step: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Action:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5943ccf3104b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_one_hot_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             self._target: agents_expected_reward})\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thalles/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thalles/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thalles/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/thalles/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thalles/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = LearningAgent(env)\n",
    "agent.game_initial_setup()\n",
    "\n",
    "DELAY = 0.05\n",
    "EPSODE_SIZE = 100000\n",
    "\n",
    "for t in range(EPSODE_SIZE):\n",
    "    step = t\n",
    "\n",
    "    agent.update(step)\n",
    "\n",
    "    sleep(DELAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = agent.exp_replay_list[0][3]\n",
    "print img.shape\n",
    "#print agent.state[:, :, 1].shape\n",
    "plt.imshow(img[:,:,3], cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
